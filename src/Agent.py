"""
Agent ç±» - æ™ºèƒ½ä½“ç¼–æ’å™¨
è´Ÿè´£åè°ƒå¤šä¸ª MCP å®¢æˆ·ç«¯å’Œ LLMï¼Œå¤„ç†å·¥å…·è°ƒç”¨å¾ªç¯
"""

import json
from typing import List, Optional, Dict, Any

from MCPClient import MCPClient
from ChatOpenAI import ChatOpenAI
from utils import log_title


class Agent:
    """
    æ™ºèƒ½ä½“ç±»ï¼Œæ•´åˆ MCP å·¥å…·å’Œ LLM è¿›è¡Œè‡ªä¸»ä»»åŠ¡æ‰§è¡Œ
    """
    
    def __init__(
        self,
        model: str,
        mcp_clients: List[MCPClient],
        system_prompt: str = '',
        context: str = ''
    ):
        """
        åˆå§‹åŒ– Agent
        
        Args:
            model: OpenAI æ¨¡å‹åç§°
            mcp_clients: MCP å®¢æˆ·ç«¯åˆ—è¡¨
            system_prompt: ç³»ç»Ÿæç¤ºè¯
            context: åˆå§‹ä¸Šä¸‹æ–‡
        """
        self.mcp_clients = mcp_clients
        self.model = model
        self.system_prompt = system_prompt
        self.context = context
        self.llm: Optional[ChatOpenAI] = None
    
    async def init(self) -> None:
        """
        åˆå§‹åŒ– Agent
        - åˆå§‹åŒ–æ‰€æœ‰ MCP å®¢æˆ·ç«¯
        - æ”¶é›†æ‰€æœ‰å·¥å…·
        - åˆ›å»º LLM å®ä¾‹
        """
        log_title('TOOLS')
        
        # åˆå§‹åŒ–æ‰€æœ‰ MCP å®¢æˆ·ç«¯
        for client in self.mcp_clients:
            await client.init()
        
        # æ”¶é›†æ‰€æœ‰å·¥å…·
        tools = []
        for client in self.mcp_clients:
            tools.extend(client.get_tools())
        
        print(f"âœ… å…±åŠ è½½ {len(tools)} ä¸ªå·¥å…·")
        for i, tool in enumerate(tools, 1):
            print(f"   {i}. {tool['name']}")
        print()
        
        # åˆ›å»º LLM å®ä¾‹
        self.llm = ChatOpenAI(
            model=self.model,
            system_prompt=self.system_prompt,
            tools=tools,
            context=self.context
        )
    
    async def close(self) -> None:
        """
        å…³é—­æ‰€æœ‰ MCP å®¢æˆ·ç«¯è¿æ¥
        """
        for client in self.mcp_clients:
            await client.close()
        print("âœ… æ‰€æœ‰ MCP è¿æ¥å·²å…³é—­")
    
    async def invoke(self, prompt: str) -> str:
        """
        æ‰§è¡Œä¸€æ¬¡å®Œæ•´çš„æ™ºèƒ½ä½“è°ƒç”¨
        - å‘é€ç”¨æˆ·è¾“å…¥
        - å¤„ç†å·¥å…·è°ƒç”¨å¾ªç¯
        - è¿”å›æœ€ç»ˆç»“æœ
        
        Args:
            prompt: ç”¨æˆ·è¾“å…¥
            
        Returns:
            æœ€ç»ˆçš„æ–‡æœ¬å“åº”
            
        Raises:
            RuntimeError: å¦‚æœ Agent æœªåˆå§‹åŒ–
        """
        if not self.llm:
            raise RuntimeError("Agent æœªåˆå§‹åŒ–ï¼Œè¯·å…ˆè°ƒç”¨ init() æ–¹æ³•")
        
        # é¦–æ¬¡å¯¹è¯
        response = await self.llm.chat(prompt)
        
        # å·¥å…·è°ƒç”¨å¾ªç¯
        while True:
            # æ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨
            if response['toolCalls'] and len(response['toolCalls']) > 0:
                # å¤„ç†æ‰€æœ‰å·¥å…·è°ƒç”¨
                for tool_call in response['toolCalls']:
                    await self._handle_tool_call(tool_call)
                
                # å·¥å…·è°ƒç”¨åï¼Œè®© LLM å¤„ç†ç»“æœå¹¶ç»§ç»­å¯¹è¯
                response = await self.llm.chat()
                continue
            
            # æ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œç»“æŸå¯¹è¯
            await self.close()
            return response['content']
    
    async def _handle_tool_call(self, tool_call: Dict[str, Any]) -> None:
        """
        å¤„ç†å•ä¸ªå·¥å…·è°ƒç”¨
        
        Args:
            tool_call: å·¥å…·è°ƒç”¨å¯¹è±¡
        """
        tool_name = tool_call['function']['name']
        tool_args_str = tool_call['function']['arguments']
        tool_id = tool_call['id']
        
        log_title('TOOL USE')
        print(f"ğŸ”§ è°ƒç”¨å·¥å…·: {tool_name}")
        print(f"ğŸ“ å‚æ•°: {tool_args_str}")
        
        # æŸ¥æ‰¾å¯¹åº”çš„ MCP å®¢æˆ·ç«¯
        mcp_client = self._find_mcp_client_for_tool(tool_name)
        
        if mcp_client:
            try:
                # è§£æå‚æ•°
                tool_args = json.loads(tool_args_str)
                
                # è°ƒç”¨å·¥å…·
                result_str = await mcp_client.call_tool(tool_name, tool_args)
                # breakpoint()
                # æ ¼å¼åŒ–ç»“æœ
                result_str = json.dumps(result_str, ensure_ascii=False, indent=2)
                print(f"âœ… ç»“æœ: {result_str[:200]}...")  # åªæ‰“å°å‰ 200 å­—ç¬¦
                
                # å°†ç»“æœè¿”å›ç»™ LLM
                self.llm.append_tool_result(tool_id, result_str)
                
            except json.JSONDecodeError as e:
                error_msg = f"å‚æ•°è§£æå¤±è´¥: {e}"
                print(f"âŒ {error_msg}")
                self.llm.append_tool_result(tool_id, error_msg)
                
            except Exception as e:
                error_msg = f"å·¥å…·è°ƒç”¨å¤±è´¥: {e}"
                print(f"âŒ {error_msg}")
                self.llm.append_tool_result(tool_id, error_msg)
        else:
            error_msg = f"æœªæ‰¾åˆ°å·¥å…·: {tool_name}"
            print(f"âŒ {error_msg}")
            self.llm.append_tool_result(tool_id, error_msg)
        
        print()  # ç©ºè¡Œåˆ†éš”
    
    def _find_mcp_client_for_tool(self, tool_name: str) -> Optional[MCPClient]:
        """
        æ ¹æ®å·¥å…·åç§°æŸ¥æ‰¾å¯¹åº”çš„ MCP å®¢æˆ·ç«¯
        
        Args:
            tool_name: å·¥å…·åç§°
            
        Returns:
            å¯¹åº”çš„ MCP å®¢æˆ·ç«¯ï¼Œå¦‚æœæœªæ‰¾åˆ°åˆ™è¿”å› None
        """
        for client in self.mcp_clients:
            tools = client.get_tools()
            if any(tool['name'] == tool_name for tool in tools):
                return client
        return None

    
    
    async def __aenter__(self):
        """æ”¯æŒå¼‚æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨"""
        await self.init()
        return self
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        """æ”¯æŒå¼‚æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨"""
        await self.close()


# ============ ä½¿ç”¨ç¤ºä¾‹ ============

async def example_usage():
    """Agent ä½¿ç”¨ç¤ºä¾‹"""
    from MCPClient import MCPClient
    
    # åˆ›å»º MCP å®¢æˆ·ç«¯
    filesystem_client = MCPClient(
        name='file',
        command='npx',
        args=[
            '-y',  # è‡ªåŠ¨ç¡®è®¤å®‰è£…ï¼ˆå¯é€‰ä½†æ¨èï¼‰
            '@modelcontextprotocol/server-filesystem',  # npm åŒ…å
            r'C:\Users\32114\Desktop\code\llm-mcp-rag-py\output'  # å…è®¸è®¿é—®çš„ç›®å½•
        ]
    )

    fetch_client = MCPClient(
        name='fetch',
        command='uvx',
        args=['mcp-server-fetch']
    )
    

    
    # åˆ›å»º Agent
    agent = Agent(
        model='gpt-4o-mini',
        mcp_clients=[fetch_client, filesystem_client]
    )

    # åˆå§‹åŒ–
    await agent.init()
    
    # æ‰§è¡Œä»»åŠ¡
    result = await agent.invoke(
        r"""çˆ¬å–https://example.com/ç½‘é¡µä¸­çš„å†…å®¹ï¼Œ
        å¹¶ä¿å­˜åˆ°C:\Users\32114\Desktop\code\llm-mcp-rag-py\outputç›®å½•ä¸‹çš„summary.txtä¸­"""
    )
    
    print(f"\næœ€ç»ˆç»“æœ: {result}")
    


if __name__ == "__main__":
    import asyncio
    asyncio.run(example_usage())

"""
æµ‹è¯• ChatOpenAI ç±»çš„å®Œæ•´åŠŸèƒ½
åŒ…æ‹¬ï¼šåŸºç¡€èŠå¤©ã€å·¥å…·è°ƒç”¨ã€æµå¼è¾“å‡º
"""

import asyncio
import json
import os
from typing import List, Dict, Any
from dotenv import load_dotenv

# å¯¼å…¥æˆ‘ä»¬å®ç°çš„æ¨¡å—
from utils import log_title
from ChatOpenAI import ChatOpenAI, Tool, ToolCall

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()


class TestChatOpenAI:
    """æµ‹è¯•ç±»"""
    
    def __init__(self):
        """åˆå§‹åŒ–æµ‹è¯•ç¯å¢ƒ"""
        # æ£€æŸ¥ç¯å¢ƒå˜é‡
        if not os.getenv("OPENAI_API_KEY"):
            raise ValueError("è¯·åœ¨ .env æ–‡ä»¶ä¸­è®¾ç½® OPENAI_API_KEY")
        
        print("âœ… ç¯å¢ƒå˜é‡æ£€æŸ¥é€šè¿‡")
    
    async def test_basic_chat(self):
        """æµ‹è¯• 1ï¼šåŸºç¡€èŠå¤©åŠŸèƒ½ï¼ˆæ— å·¥å…·ï¼‰"""
        log_title("æµ‹è¯• 1: åŸºç¡€èŠå¤©")
        
        chat = ChatOpenAI(
            model="gpt-4o-mini",  # ä½¿ç”¨æ›´ç»æµçš„æ¨¡å‹
            system_prompt="ä½ æ˜¯ä¸€ä¸ªå‹å¥½çš„åŠ©æ‰‹ï¼Œå›ç­”è¦ç®€æ´ã€‚",
        )
        
        response = await chat.chat("ç”¨ä¸€å¥è¯ä»‹ç»ä»€ä¹ˆæ˜¯ RAGï¼Ÿ")
        
        print(f"\n\nâœ… å“åº”å†…å®¹: {response['content'][:100]}...")
        print(f"âœ… å·¥å…·è°ƒç”¨æ•°é‡: {len(response['toolCalls'])}")
        assert response['content'], "å“åº”å†…å®¹ä¸åº”ä¸ºç©º"
        assert len(response['toolCalls']) == 0, "ä¸åº”æœ‰å·¥å…·è°ƒç”¨"
        print("âœ… æµ‹è¯• 1 é€šè¿‡ï¼\n")
    
    async def test_multi_turn_chat(self):
        """æµ‹è¯• 2ï¼šå¤šè½®å¯¹è¯"""
        log_title("æµ‹è¯• 2: å¤šè½®å¯¹è¯")
        
        chat = ChatOpenAI(
            model="gpt-4o-mini",
            system_prompt="ä½ æ˜¯ä¸€ä¸ªæ•°å­¦åŠ©æ‰‹ã€‚",
        )
        
        # ç¬¬ä¸€è½®
        response1 = await chat.chat("3 + 5 ç­‰äºå¤šå°‘ï¼Ÿ")
        print(f"\nç¬¬ä¸€è½®å“åº”: {response1['content'][:50]}")
        
        # ç¬¬äºŒè½®ï¼ˆåŸºäºä¸Šä¸‹æ–‡ï¼‰
        response2 = await chat.chat("å†åŠ  10 å‘¢ï¼Ÿ")
        print(f"\nç¬¬äºŒè½®å“åº”: {response2['content'][:50]}")
        
        assert response1['content'], "ç¬¬ä¸€è½®å“åº”ä¸åº”ä¸ºç©º"
        assert response2['content'], "ç¬¬äºŒè½®å“åº”ä¸åº”ä¸ºç©º"
        print("\nâœ… æµ‹è¯• 2 é€šè¿‡ï¼\n")
    
    async def test_tool_calling(self):
        """æµ‹è¯• 3ï¼šå·¥å…·è°ƒç”¨åŠŸèƒ½"""
        log_title("æµ‹è¯• 3: å·¥å…·è°ƒç”¨")
        
        # å®šä¹‰æµ‹è¯•å·¥å…·
        tools: List[Tool] = [
            {
                "name": "search_database",
                "description": "åœ¨çŸ¥è¯†åº“ä¸­æœç´¢ç›¸å…³æ–‡æ¡£",
                "inputSchema": {
                    "type": "object",
                    "properties": {
                        "query": {
                            "type": "string",
                            "description": "æœç´¢æŸ¥è¯¢å­—ç¬¦ä¸²"
                        },
                        "limit": {
                            "type": "integer",
                            "description": "è¿”å›ç»“æœæ•°é‡é™åˆ¶",
                            "default": 5
                        }
                    },
                    "required": ["query"]
                }
            },
            {
                "name": "get_current_time",
                "description": "è·å–å½“å‰æ—¶é—´",
                "inputSchema": {
                    "type": "object",
                    "properties": {
                        "timezone": {
                            "type": "string",
                            "description": "æ—¶åŒºï¼Œå¦‚ 'Asia/Shanghai'"
                        }
                    }
                }
            }
        ]
        
        chat = ChatOpenAI(
            model="openai/gpt-4o-mini",
            system_prompt="ä½ æ˜¯ä¸€ä¸ªåŠ©æ‰‹ï¼Œå¯ä»¥ä½¿ç”¨å·¥å…·æ¥å¸®åŠ©ç”¨æˆ·ã€‚",
            tools=tools
        )
        
        # å‘é€ä¼šè§¦å‘å·¥å…·è°ƒç”¨çš„æ¶ˆæ¯
        response = await chat.chat("è¯·å¸®æˆ‘æœç´¢å…³äº'å‘é‡æ•°æ®åº“'çš„æ–‡æ¡£ï¼Œè¿”å› 3 æ¡ç»“æœ")
        
        print(f"\n\nâœ… å“åº”å†…å®¹: {response['content']}")
        print(f"âœ… å·¥å…·è°ƒç”¨æ•°é‡: {len(response['toolCalls'])}")
        
        # å¤„ç†å·¥å…·è°ƒç”¨
        if response['toolCalls']:
            for tool_call in response['toolCalls']:
                tool_name = tool_call['function']['name']
                tool_args_str = tool_call['function']['arguments']
                
                print(f"\nğŸ“ å·¥å…·è°ƒç”¨:")
                print(f"   - ID: {tool_call['id']}")
                print(f"   - åç§°: {tool_name}")
                print(f"   - å‚æ•°: {tool_args_str}")
                
                # è§£æå‚æ•°
                tool_args = json.loads(tool_args_str)
                
                # æ¨¡æ‹Ÿå·¥å…·æ‰§è¡Œ
                tool_result = self.mock_tool_execution(tool_name, tool_args)
                print(f"   - æ‰§è¡Œç»“æœ: {tool_result[:100]}...")
                
                # å°†ç»“æœè¿”å›ç»™ LLM
                chat.append_tool_result(tool_call['id'], tool_result)
            
            # ç»§ç»­å¯¹è¯ï¼Œè®© LLM å¤„ç†å·¥å…·ç»“æœ
            log_title("LLM å¤„ç†å·¥å…·ç»“æœ")
            final_response = await chat.chat()
            print(f"\n\nâœ… æœ€ç»ˆå“åº”: {final_response['content']}")
            
            assert len(response['toolCalls']) > 0, "åº”è¯¥æœ‰å·¥å…·è°ƒç”¨"
            print("\nâœ… æµ‹è¯• 3 é€šè¿‡ï¼\n")
        else:
            print("âš ï¸ è­¦å‘Šï¼šLLM æ²¡æœ‰è°ƒç”¨å·¥å…·ï¼Œå¯èƒ½éœ€è¦è°ƒæ•´æç¤ºè¯")
    
    def mock_tool_execution(self, tool_name: str, args: Dict[str, Any]) -> str:
        """æ¨¡æ‹Ÿå·¥å…·æ‰§è¡Œ"""
        if tool_name == "search_database":
            query = args.get("query", "")
            limit = args.get("limit", 5)
            return json.dumps({
                "results": [
                    {"title": f"å‘é‡æ•°æ®åº“æŠ€æœ¯ç»¼è¿° {i+1}", "score": 0.95 - i*0.1}
                    for i in range(min(limit, 3))
                ],
                "total": limit
            }, ensure_ascii=False)
        
        elif tool_name == "get_current_time":
            from datetime import datetime
            timezone = args.get("timezone", "UTC")
            return json.dumps({
                "time": datetime.now().isoformat(),
                "timezone": timezone
            })
        
        return json.dumps({"error": "æœªçŸ¥å·¥å…·"})
    
    async def test_system_prompt_and_context(self):
        """æµ‹è¯• 4ï¼šç³»ç»Ÿæç¤ºè¯å’Œåˆå§‹ä¸Šä¸‹æ–‡"""
        log_title("æµ‹è¯• 4: ç³»ç»Ÿæç¤ºè¯å’Œä¸Šä¸‹æ–‡")
        
        chat = ChatOpenAI(
            model="gpt-4o-mini",
            system_prompt="ä½ æ˜¯ä¸€ä¸ªæµ·ç›—èˆ¹é•¿ï¼Œè¯´è¯è¦æœ‰æµ·ç›—é£æ ¼ã€‚",
            context="æˆ‘ä»¬æ­£åœ¨å¯»æ‰¾ä¼ è¯´ä¸­çš„å®è—ã€‚"
        )
        
        response = await chat.chat("ä½ å¥½ï¼")
        
        print(f"\n\nâœ… å“åº”å†…å®¹: {response['content']}")
        print("âœ… æµ‹è¯• 4 é€šè¿‡ï¼\n")
    
    async def run_all_tests(self):
        """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
        log_title("å¼€å§‹æµ‹è¯• ChatOpenAI ç±»")
        
        try:
            await self.test_basic_chat()
            await self.test_multi_turn_chat()
            await self.test_tool_calling()
            await self.test_system_prompt_and_context()
            
            log_title("æ‰€æœ‰æµ‹è¯•é€šè¿‡ âœ…")
            
        except Exception as e:
            log_title("æµ‹è¯•å¤±è´¥ âŒ")
            print(f"é”™è¯¯: {str(e)}")
            import traceback
            traceback.print_exc()


async def main():
    """ä¸»å‡½æ•°"""
    tester = TestChatOpenAI()
    await tester.run_all_tests()


if __name__ == "__main__":
    print("=" * 80)
    print("ChatOpenAI åŠŸèƒ½æµ‹è¯•")
    print("=" * 80)
    print()
    
    asyncio.run(main())
